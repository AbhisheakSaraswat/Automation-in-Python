{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract CIR files (only applicable for ADF)\n",
    "#### Input: List of Loan IDs and their XML Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where you want to store the CIRs\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File which contains two columns, loan_ref_no and xml_data_file (XML Link)\n",
    "user_info = pd.read_csv('all_bureau_adf_jan19_L6m.csv')\n",
    "\n",
    "user_info = user_info.sort_values('created', ascending = False)\n",
    "\n",
    "user_info = user_info.drop_duplicates(subset = 'msisdn')\n",
    "\n",
    "DIR = \"C:/Users/Seynse/Desktop/Airtel/CIRs/all_bureau_adf_jan19_L6M/\"\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "\n",
    "def getXMLdata(loan_id, xml_url):\n",
    "    import requests\n",
    "    response = requests.get(xml_url)\n",
    "    with open(DIR + loan_id + '.txt', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "user_info.apply(lambda x: (getXMLdata(str(x[('msisdn')]).replace('.0',''), x[('cir_file_url')])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'C:/Users/Seynse/Desktop/Airtel/CIRs/all_bureau_adf_jan19_L6M/'\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "loan_names = onlyfiles\n",
    "loan_ids = pd.DataFrame({'loan_ref_no':loan_names})\n",
    "loan_ids['loan_ref_no'] = loan_ids.apply(lambda x: str(x['loan_ref_no']).replace('.txt',''), axis=1)\n",
    "loan_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and/or Convert parsed response to JSON for data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "user = os.getenv('username')\n",
    "\n",
    "running_for = input('ADF/LOS: ') # Options: (LOS/ADF)\n",
    "\n",
    "if running_for == 'ADF':\n",
    "    # Location of the CIR text files\n",
    "    mypath = 'C:/Users/'+user+'/Desktop/LOS Data/Monday Report/XML_extract/new_adf1/'\n",
    "\n",
    "    onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "    loan_names = onlyfiles\n",
    "    loan_ids = pd.DataFrame({'loan_ref_no':loan_names})\n",
    "\n",
    "    i=0\n",
    "    while i < len(onlyfiles):\n",
    "        onlyfiles[i] = mypath+onlyfiles[i]\n",
    "        i+=1\n",
    "\n",
    "    file_names = pd.DataFrame({'path':onlyfiles})\n",
    "\n",
    "    combine = pd.merge(loan_ids, file_names, left_index=True, right_index=True)\n",
    "\n",
    "    # Date Reported\n",
    "\n",
    "    def read_cir(path,loan_ref_no):\n",
    "        file = open(path, 'r')\n",
    "        return file.read() \n",
    "\n",
    "    def read_response(trial,loan_ref_no):\n",
    "        try:\n",
    "            abc = str(trial)\n",
    "            length = abc.find('{')\n",
    "            cut = abc[length:-1]\n",
    "            return cut\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    combine['parsed_response'] = combine.apply(lambda x: (read_cir(x[('path')],x[('loan_ref_no')])),axis=1)\n",
    "    combine['final_response'] = combine.apply(lambda x: (read_response(x[('parsed_response')],x[('loan_ref_no')])),axis=1)\n",
    "\n",
    "elif running_for == 'LOS':\n",
    "    combine = pd.read_csv('C:/Users/'+user+'/Seynse/parsed_cibil_24jul.csv')\n",
    "    combine = combine.drop_duplicates('loan_ref_no')\n",
    "    combine = combine.rename(columns={\"parsed_response\": \"final_response\"})\n",
    "    \n",
    "else:\n",
    "    print(\"Sorry, invalid input; Cannot Proceed Further!\")\n",
    "    sys.exit()\n",
    "\n",
    "print(len(combine))\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIR Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Reported\n",
    "def date_process(trial,loan_ref_no):\n",
    "    global date_processed\n",
    "    try:\n",
    "        if running_for == 'ADF':\n",
    "            trial = trial + \"}\"\n",
    "            cut = str(trial)\n",
    "        elif running_for == 'LOS':\n",
    "            cut = trial\n",
    "        j = json.loads(cut)\n",
    "        date = j['TUEF']['date_processed']\n",
    "    except:\n",
    "        date = ''\n",
    "    list_date = [loan_ref_no, date]\n",
    "    df = pd.DataFrame(np.array(list_date).reshape(1,2), columns = ['Loan ID','Date Processed'])\n",
    "    if len(date_processed) == 0:\n",
    "        date_processed = df\n",
    "    else:\n",
    "        date_processed = date_processed.append(df)\n",
    "    return 0\n",
    "\n",
    "# Total Loans Ever\n",
    "def total_loans(trial,loan_ref_no):\n",
    "    global all_loans\n",
    "    try:\n",
    "        if running_for == 'ADF':\n",
    "            trial = trial + \"}\"\n",
    "            cut = str(trial)\n",
    "        elif running_for == 'LOS':\n",
    "            cut = trial\n",
    "        j = json.loads(cut)\n",
    "        total_loans_ever = len((j['TL']))\n",
    "        k = 0\n",
    "        while k < total_loans_ever:\n",
    "            loan_type = j['TL'][k]['account_type']['display']\n",
    "            loan_status = j['TL'][k]['live_or_close']['display']\n",
    "            secured_or_unsecured = j['TL'][k]['secured_or_unsecured']\n",
    "            credit_limit = j['TL'][k]['credit_limit']\n",
    "            sanctioned_limit = j['TL'][k]['sanctioned_amount']\n",
    "            date_opened = j['TL'][k]['date_opened']\n",
    "            amount_overdue = j['TL'][k]['amount_overdue']\n",
    "            settlement_amount = j['TL'][k]['settlement_amount']\n",
    "            written_off_amount_total = j['TL'][k]['written_off_amount_total']\n",
    "            suit_filed = j['TL'][k]['suit_filed']['display']\n",
    "            local_loan = [loan_ref_no, k, loan_type, loan_status, secured_or_unsecured, credit_limit, sanctioned_limit, date_opened, amount_overdue, settlement_amount, written_off_amount_total, suit_filed]\n",
    "            df = pd.DataFrame(np.array(local_loan).reshape(1,12), columns = ['Loan ID','Count','Type','Loan Status','Secured or Unsecured','Credit Limit','Sanctioned Limit','Date Opened',' Amount Overdue', 'Settlement Amount','Write-off Amount','Suit Filed'])\n",
    "            if len(all_loans) == 0:\n",
    "                all_loans = df\n",
    "            else:\n",
    "                all_loans = all_loans.append(df)\n",
    "            k+=1\n",
    "        return 0\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Total Inquiries Ever\n",
    "def total_enq(trial,loan_ref_no):\n",
    "    global all_enq\n",
    "    try:\n",
    "        if running_for == 'ADF':\n",
    "            trial = trial + \"}\"\n",
    "            cut = str(trial)\n",
    "        elif running_for == 'LOS':\n",
    "            cut = trial\n",
    "        j = json.loads(cut)\n",
    "        total_inq_ever = len((j['IQ']))\n",
    "        k = 0\n",
    "        while k < total_inq_ever:\n",
    "            loan_type = j['IQ'][k]['enquiry_purpose']['display']\n",
    "            loan_amount = j['IQ'][k]['enquiry_amount']\n",
    "            date_of_enquiry = j['IQ'][k]['date_of_enquiry']\n",
    "            local_loan = [loan_ref_no, loan_type, loan_amount, date_of_enquiry]\n",
    "            df = pd.DataFrame(np.array(local_loan).reshape(1,4), columns = ['Loan ID','Type','Loan Amount','Date of Enquiry'])\n",
    "            if len(all_enq) == 0:\n",
    "                all_enq = df\n",
    "            else:\n",
    "                all_enq = all_enq.append(df)\n",
    "            k+=1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# DPD Status for all loans\n",
    "def total_dpd(trial,loan_ref_no):\n",
    "    global i\n",
    "    print('DPD ',i)\n",
    "    i+=1\n",
    "    global all_dpd\n",
    "    try:\n",
    "        if running_for == 'ADF':\n",
    "            trial = trial + \"}\"\n",
    "            cut = str(trial)\n",
    "        elif running_for == 'LOS':\n",
    "            cut = trial\n",
    "        j = json.loads(cut)\n",
    "        total_loans_ever = len((j['TL']))\n",
    "        k = 0\n",
    "        while k < total_loans_ever:\n",
    "            loan_type = j['TL'][k]['account_type']['display']\n",
    "            total_dpd_values = len(j['TL'][k]['dpd_values'])\n",
    "            date_opened = j['TL'][k]['date_opened']\n",
    "            x = 0\n",
    "            while x < total_dpd_values:\n",
    "                dpd = j['TL'][k]['dpd_values'][x]['dpd']\n",
    "                month = j['TL'][k]['dpd_values'][x]['month']\n",
    "                local_loan = [loan_ref_no, k, date_opened, loan_type, total_dpd_values, x, dpd, month]\n",
    "                df = pd.DataFrame(np.array(local_loan).reshape(1,8), columns = ['Loan ID','Count','Date Opened','Type','Total DPD Values','Counter','DPD','Month'])\n",
    "                if len(all_dpd) == 0:\n",
    "                    all_dpd = df\n",
    "                else:\n",
    "                    all_dpd = all_dpd.append(df)\n",
    "                x+=1\n",
    "            k+=1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "i=0\n",
    "date_processed = pd.DataFrame()\n",
    "combine['extract'] = combine.apply(lambda x: (date_process(x[('final_response')],x[('loan_ref_no')])),axis=1)\n",
    "\n",
    "i=0\n",
    "all_enq = pd.DataFrame()\n",
    "combine['extract'] = combine.apply(lambda x: (total_enq(x[('final_response')],x[('loan_ref_no')])),axis=1)\n",
    "\n",
    "i=0\n",
    "all_loans = pd.DataFrame()\n",
    "combine['extract'] = combine.apply(lambda x: (total_loans(x[('final_response')],x[('loan_ref_no')])),axis=1)\n",
    "\n",
    "i=0\n",
    "all_dpd = pd.DataFrame()\n",
    "combine['extract'] = combine.apply(lambda x: (total_dpd(x[('final_response')],x[('loan_ref_no')])),axis=1)\n",
    "\n",
    "def date_convert(inp_date):\n",
    "    try:\n",
    "        new_date = datetime.datetime.strptime(inp_date,'%d-%m-%Y').date()\n",
    "    except:\n",
    "        try:\n",
    "            new_date = datetime.datetime.strptime(inp_date,'%d-%m-%y').date()\n",
    "        except:\n",
    "            new_date = inp_date\n",
    "    return new_date\n",
    "\n",
    "date_processed['Date Processed'] = date_processed.apply(lambda x: date_convert(x['Date Processed']), axis=1)\n",
    "all_enq['Date of Enquiry'] = all_enq.apply(lambda x: date_convert(x['Date of Enquiry']), axis=1)\n",
    "all_loans['Date Opened'] = all_loans.apply(lambda x: date_convert(x['Date Opened']), axis=1)\n",
    "all_dpd['Date Opened'] = all_dpd.apply(lambda x: date_convert(x['Date Opened']), axis=1)\n",
    "\n",
    "all_dpd['Month'] = '01-'+all_dpd['Month']\n",
    "all_dpd['Month'] = all_dpd.apply(lambda x: date_convert(x['Month']), axis=1)\n",
    "all_dpd['Month'] = all_dpd['Month'] + relativedelta(day=1, months=+1, days=-1)\n",
    "all_dpd['End of Date'] = all_dpd['Date Opened'] + relativedelta(day=1, months=+1, days=-1)\n",
    "\n",
    "def flag_create(diff, x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        if diff > x:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        if x == 'XXX':\n",
    "            return 0\n",
    "        elif x == 'STD':\n",
    "            return 0\n",
    "        elif x in ['SUB','DBT','LSS']:\n",
    "            return 1\n",
    "            \n",
    "\n",
    "all_dpd['diff'] = all_dpd['Month'] - all_dpd['End of Date']\n",
    "all_dpd['12_month'] = all_dpd.apply(lambda x: flag_create(x['diff'].days,365), axis=1)\n",
    "all_dpd['30+_flag'] = all_dpd.apply(lambda x: flag_create(30, x['DPD']), axis=1)\n",
    "all_dpd['90+_flag'] = all_dpd.apply(lambda x: flag_create(90, x['DPD']), axis=1)\n",
    "\n",
    "all_enq = pd.merge(all_enq, date_processed, on = 'Loan ID', how = 'left')\n",
    "all_enq['diff'] = all_enq['Date Processed'] - all_enq['Date of Enquiry']\n",
    "all_enq['30day_flag'] = all_enq.apply(lambda x: flag_create(x['diff'].days,30), axis=1)\n",
    "all_enq['60day_flag'] = all_enq.apply(lambda x: flag_create(x['diff'].days,60), axis=1)\n",
    "all_enq['90day_flag'] = all_enq.apply(lambda x: flag_create(x['diff'].days,90), axis=1)\n",
    "\n",
    "loan_cat = pd.read_csv('loan_category_cibil.csv')\n",
    "all_loans = pd.merge(all_loans, loan_cat, on = 'Type', how = 'left')\n",
    "all_loans['Category'] = all_loans['Category'].fillna('Other')\n",
    "\n",
    "all_enq = all_enq.replace({'.txt': ''}, regex=True)\n",
    "all_loans = all_loans.replace({'.txt': ''}, regex=True)\n",
    "all_dpd = all_dpd.replace({'.txt': ''}, regex=True)\n",
    "date_processed = date_processed.replace({'.txt': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_date = datetime.datetime.today().strftime('%d%b%y') #'01Feb18'\n",
    "\n",
    "all_enq.to_excel('enq_all' + curr_date + '.xlsx', index = False)\n",
    "all_loans.to_excel('loans_all' + curr_date + '.xlsx', index = False)\n",
    "all_dpd.to_excel('dpd_all' + curr_date + '.xlsx', index = False)\n",
    "date_processed.to_excel('date_process' + curr_date + '.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Deprecated) Checks For ADF Pre-Approved\n",
    "PS - This is redundant since this eligibility data is already readily available in the DB for the customers with CIBIL details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dpd = pd.read_excel('dpd_score_inp_1212_v1.xlsx')\n",
    "all_enq = pd.read_excel('enq_score_inp_1212_v1.xlsx')\n",
    "all_loans = pd.read_excel('loans_score_inp_1212_v1.xlsx')\n",
    "date_processed = pd.read_excel('date_process_score_inp_1212_v1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_concat(a,b):\n",
    "    return str(a) + str(b)\n",
    "\n",
    "all_dpd['ID'] = all_dpd.apply(lambda x: str_concat(x['Loan ID'],x['Count']),axis=1)\n",
    "all_loans['ID'] = all_loans.apply(lambda x: str_concat(x['Loan ID'],x['Count']),axis=1)\n",
    "loan_merge = all_loans.drop(['Unnamed: 0','Loan ID','Count','Date Opened','Type'],axis=1)\n",
    "dpd_loans = pd.merge(all_dpd, loan_merge, on = 'ID', how = 'left')\n",
    "\n",
    "def flag_create(diff, x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        if diff > x:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        if x == 'XXX':\n",
    "            return 0\n",
    "        elif x == 'STD':\n",
    "            return 0\n",
    "        elif x in ['SUB','DBT','LSS']:\n",
    "            return 1\n",
    "            \n",
    "def days_removal(days):\n",
    "    try:\n",
    "        loc = days.find('d')-1\n",
    "        day = int(days[:loc])\n",
    "        return day\n",
    "    except Exception as e: \n",
    "        print(days,e)\n",
    "        return None\n",
    "            \n",
    "dpd_loans['days'] = dpd_loans.apply(lambda x: days_removal(str(x['diff'])),axis=1)\n",
    "dpd_loans['3_month'] = dpd_loans.apply(lambda x: flag_create(x['days'],91), axis=1)\n",
    "dpd_loans['6_month'] = dpd_loans.apply(lambda x: flag_create(x['days'],182), axis=1)\n",
    "\n",
    "def exemption_flag(type_loan, amt_ovd):\n",
    "    if type_loan == 'Credit Card':\n",
    "        if amt_ovd > 5000:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if amt_ovd > 500:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1        \n",
    "\n",
    "def curr_del(exempt, status, dpd):\n",
    "    if exempt == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        if status == 'Live Account':\n",
    "            if dpd in ['SUB','DBT','LSS','SMA']:\n",
    "                return 1\n",
    "            elif dpd in ['XXX','STD']:\n",
    "                return 0\n",
    "            else:\n",
    "                try:\n",
    "                    dpd=int(dpd)\n",
    "                    if dpd > 0:\n",
    "                        return 1\n",
    "                    else:\n",
    "                        return 0\n",
    "                except Exception as e:\n",
    "                    print(dpd,e)\n",
    "        else:\n",
    "            return 0\n",
    "                    \n",
    "def settle_etc(settle,write_off,suit_filed):\n",
    "    if settle > 0 or write_off > 0 or suit_filed in ['Suit filed','Wilful default','Suit filed (Wilful default)']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dpd_loans['settle_etc'] = dpd_loans.apply(lambda x: settle_etc(x['Settlement Amount'],x['Write-off Amount'],x['Suit Filed']),axis=1)\n",
    "dpd_loans['exempt'] = dpd_loans.apply(lambda x: exemption_flag(x['Type'],x[' Amount Overdue']),axis=1)\n",
    "dpd_loans['curr_del'] = dpd_loans.apply(lambda x: curr_del(x['exempt'],x['Loan Status'],x['DPD']),axis=1)\n",
    "curr_del_df = dpd_loans[dpd_loans['curr_del']!=0][['Loan ID','curr_del']]\n",
    "curr_del_df = curr_del_df.drop_duplicates()\n",
    "L3_30 = dpd_loans[(dpd_loans['30+_flag'] == 1) & (dpd_loans['3_month'] == 1) & (dpd_loans['exempt'] == 0)][['Loan ID','30+_flag']].drop_duplicates()\n",
    "L12_90 = dpd_loans[(dpd_loans['90+_flag'] == 1) & (dpd_loans['12_month'] == 1) & (dpd_loans['exempt'] == 0)][['Loan ID','90+_flag']].drop_duplicates()\n",
    "settle_etc_df = dpd_loans[(dpd_loans['settle_etc'] == 1) & (dpd_loans['12_month'] == 1)][['Loan ID','settle_etc']].drop_duplicates()\n",
    "settle_etc_df = settle_etc_df.drop_duplicates()\n",
    "final_table = pd.merge(date_processed, curr_del_df, on = 'Loan ID', how = 'left').fillna(0).drop(['Unnamed: 0'],axis=1)\n",
    "final_table = pd.merge(final_table, L3_30, on = 'Loan ID', how = 'left').fillna(0)\n",
    "final_table = pd.merge(final_table, L12_90, on = 'Loan ID', how = 'left').fillna(0)\n",
    "final_table = pd.merge(final_table, settle_etc_df, on = 'Loan ID', how = 'left').fillna(0)\n",
    "# final_table.to_excel('ADF_pre_app_analysis.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
